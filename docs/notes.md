1. we need to wrap database interactions with observability. Ideally, we can identify each call based on what line of service/module code interacts with it and have 50 95 and 99 percentile mentrics
2. kafka messages in the data pipeline (up to including persistence and algos) shoud be keyd by the client and symbol to maintain order when consuming messages. These messages should also be processed sequentially and not concurrently or paralelly
3. I see that redis keys are an issue when running test, why? the key should contain the tenant and event ids which should always be generated uniquely
4. All fraud detection algorithm implementations must be pure in-memory computations. No external service calls (Redis, DB, HTTP) inside evaluate_window(). All data the algo needs must come from the events list and the thresholds dict passed in. This keeps algos fast (no I/O latency), trivially testable (no mocks needed), and parallelizable in the future. The sliding window engine manages the buffer and config lookups; algos just receive data and return alerts.
5. we need an alert management service that reads them from kafka and inserts them to postgres. It should also have some alert aggregation mechanims that aggregates alerts into cases that are also displayed in the UI. we need to plan a design for it and define the logic well